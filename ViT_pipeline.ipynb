{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "_-vdFj9Av_k-",
    "outputId": "5400c3e5-152e-450c-b33e-642507a6e96d"
   },
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# ViT forecasting template (GPT-OSS style; no quantization, loads once)\n",
    "# ======================================================================\n",
    "\n",
    "# --- Imports ---\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# --- Global results dict + logger ---\n",
    "RESULTS = {}\n",
    "\n",
    "def log_simple_result(results_dict, dataset_name, horizon, mae, rmse, mape, r2):\n",
    "    results_dict[dataset_name] = {\n",
    "        \"horizon\": horizon,\n",
    "        \"MAE\": round(mae, 2),\n",
    "        \"RMSE\": round(rmse, 2),\n",
    "        \"MAPE (%)\": round(mape, 2),\n",
    "        \"RÂ²\": round(r2, 4),\n",
    "    }\n",
    "\n",
    "# --- Load ViT once ---\n",
    "MODEL_ID = \"google/vit-base-patch16-224\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
    "vit = ViTForImageClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=1,                 # we output a single scalar\n",
    "    ignore_mismatched_sizes=True  # swap the head cleanly\n",
    ")\n",
    "# Replace/ensure a 1-dim head; keep it simple and predictable\n",
    "in_features = vit.classifier.in_features\n",
    "vit.classifier = nn.Linear(in_features, 1)\n",
    "vit.eval().to(DEVICE)\n",
    "\n",
    "# 16x16 = 256 tokens window -> 224x224 expected by ViT\n",
    "IMAGE_SIZE = 16\n",
    "PATCH_WINDOW = IMAGE_SIZE * IMAGE_SIZE\n",
    "resize = T.Resize((224, 224), antialias=True)\n",
    "\n",
    "# --- Forecasting function ---\n",
    "def vit_prediction(\n",
    "    dataset,\n",
    "    horizon=12,\n",
    "    frequency=\"M\",\n",
    "    dataset_name=None,\n",
    "    results_dict=RESULTS,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    dataset: callable -> (train_df, test_df) with columns ['unique_id','ds','y']\n",
    "    Returns RESULTS dict and shows a plot.\n",
    "    The ViT consumes a 16x16 grid of the last 256 normalized values as an image.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Load data\n",
    "    train_df, test_df = dataset(horizon=horizon)\n",
    "    y_train = train_df[\"y\"].values.astype(float)\n",
    "    y_test  = test_df[\"y\"].values.astype(float)\n",
    "\n",
    "    # 2) Normalize on TRAIN only (avoid leakage)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_train_norm = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Build initial 256-length window from tail of train (pad with zeros if short)\n",
    "    if len(y_train_norm) < PATCH_WINDOW:\n",
    "        window = np.pad(y_train_norm, (PATCH_WINDOW - len(y_train_norm), 0), mode=\"constant\")\n",
    "    else:\n",
    "        window = y_train_norm[-PATCH_WINDOW:].copy()\n",
    "\n",
    "    # 3) Helper: predict one step from a 256-length window\n",
    "    torch.manual_seed(seed)\n",
    "    def predict_next_point_01(input_seq_256: np.ndarray) -> float:\n",
    "        img = input_seq_256.reshape(IMAGE_SIZE, IMAGE_SIZE)\n",
    "        # to 1x3xHxW tensor\n",
    "        tensor_img = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        tensor_img = tensor_img.repeat(1, 3, 1, 1)\n",
    "        tensor_img = resize(tensor_img).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = vit(tensor_img)\n",
    "            # map to [0,1] to be safe (the head is linear)\n",
    "            val01 = torch.sigmoid(out.logits.squeeze()).item()\n",
    "        return float(val01)\n",
    "\n",
    "    # 4) Rollout horizon steps\n",
    "    preds_norm = []\n",
    "    cur = window.copy()\n",
    "    for _ in range(horizon):\n",
    "        nxt = predict_next_point_01(cur)\n",
    "        preds_norm.append(nxt)\n",
    "        # slide window\n",
    "        cur = np.roll(cur, -1)\n",
    "        cur[-1] = nxt\n",
    "\n",
    "    # 5) Inverse scale predictions to original scale (using TRAIN scaler)\n",
    "    y_pred = scaler.inverse_transform(np.array(preds_norm).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # 6) Metrics vs test set\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        mape = np.nanmean(np.abs((y_test - y_pred) / y_test) * 100.0)\n",
    "        if np.isnan(mape):\n",
    "            mape = float(\"inf\")\n",
    "    ss_res = np.sum((y_test - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot != 0 else float(\"nan\")\n",
    "\n",
    "    # 7) Log\n",
    "    name = dataset_name or getattr(dataset, \"__name__\", \"unnamed_dataset\")\n",
    "    log_simple_result(results_dict, name, horizon, mae, rmse, mape, r2)\n",
    "\n",
    "    # 8) Plot\n",
    "        # --- Professional style plot ---\n",
    "    history_color = '#1b9e77'   # teal\n",
    "    observed_color = '#d95f02'  # muted orange\n",
    "    forecast_color = '#7570b3'  # muted purple\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    ax.plot(train_df['ds'], y_train, label=\"Historical Data\",\n",
    "            color=history_color, linewidth=2)\n",
    "    ax.plot(test_df['ds'], y_test, label=\"Observed Future\",\n",
    "            color=observed_color, linewidth=2,)\n",
    "    ax.plot(test_df['ds'], y_pred, label=\"Model Forecast\",\n",
    "            color=forecast_color, linewidth=2, linestyle='--')\n",
    "\n",
    "    ax.set_title(f\"Forecasting Monthly Air Passenger Counts Using ViT (H = {horizon})\",\n",
    "                 fontsize=14, fontweight='bold', pad=15)\n",
    "    ax.set_xlabel(\"Date\", fontsize=12)\n",
    "    ax.set_ylabel(\"Number of Passengers\", fontsize=12)\n",
    "\n",
    "    ax.legend(fontsize=11, frameon=True, loc='upper left')\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "    ax.margins(x=0.02)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ViT_forecast.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "# --- Dataset loader (AirPassengers; Aileen Nielsen CSV like your snippet) ---\n",
    "def load_air_passengers(horizon=12, unique_id=\"AP1\"):\n",
    "    url = \"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\"\n",
    "    df = pd.read_csv(url, header=0)\n",
    "    df.columns = [\"ds\", \"y\"]\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"], format=\"%Y-%m\")\n",
    "\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df  = df.iloc[-horizon:].copy()\n",
    "    train_df[\"unique_id\"] = unique_id\n",
    "    test_df[\"unique_id\"]  = unique_id\n",
    "    return train_df[[\"unique_id\",\"ds\",\"y\"]], test_df[[\"unique_id\",\"ds\",\"y\"]]\n",
    "\n",
    "# --- Example run ---\n",
    "if __name__ == \"__main__\":\n",
    "    vit_prediction(load_air_passengers, horizon=24, frequency=\"M\")\n",
    "    print(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "_sMWo7qpwFke",
    "outputId": "907192d8-eac5-4e9b-a0bd-3decbdc2cd71"
   },
   "outputs": [],
   "source": [
    "def load_temperature(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Temperature'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Temperature:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_temperature, horizon=24, frequency=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "te_G0wvkw_g-",
    "outputId": "33d91a36-fe76-4c83-ff22-612b381b8c05"
   },
   "outputs": [],
   "source": [
    "def load_air_sunsopts(horizon=24, unique_id=\"AP1\"):\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Sunspots.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    print(df.shape)\n",
    "\n",
    "    # Standardize column names\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"Monthly Mean Total Sunspot Number\": \"y\"})\n",
    "    print('Mean: ', df['y'].mean())\n",
    "\n",
    "    # Split train/test\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_air_sunsopts, horizon=120, frequency=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "-39e1O3dE_aY",
    "outputId": "d8b5f1cc-1cd0-431c-91a9-d2bc5e9b29fc"
   },
   "outputs": [],
   "source": [
    "def load_temp(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/temp.csv\")\n",
    "\n",
    "    # Remove unnamed columns\n",
    "    if 'Unnamed: 2' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 2'])\n",
    "\n",
    "    # Parse date safely\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates (like the description text)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"temp\": \"y\"})\n",
    "\n",
    "    # Convert 'y' to numeric, coercing errors to NaN and dropping them\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_temp, frequency='D', horizon=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "tRAzfI7GFD6g",
    "outputId": "a8587ad6-bf8f-47d4-ded1-211436c09bdc"
   },
   "outputs": [],
   "source": [
    "def load_temperature(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Temperature'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Temperature:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_temperature, frequency='M', horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "id": "uh-ot2yCFGYT",
    "outputId": "a79ae205-2a02-4d28-b9fa-4086a9d035ae"
   },
   "outputs": [],
   "source": [
    "def load_precipitation(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Precipitation'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Precipitation:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_precipitation, frequency='M', horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cSlTqSMqFJ1d",
    "outputId": "dad716a4-e964-4335-c764-7cba1dfba065"
   },
   "outputs": [],
   "source": [
    "def load_humidity(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Specific Humidity'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Specific Humidity:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_humidity, frequency='M', horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-B0IPkYMFNB8",
    "outputId": "e1405a35-2d5b-4803-90ba-25fcbcfb128a"
   },
   "outputs": [],
   "source": [
    "def load_relative_humidity(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Relative Humidity'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Relative Humidity:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_relative_humidity, frequency='M', horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pti701esFRjI",
    "outputId": "fd3d365b-1b77-47b6-c739-d2658944c0e1"
   },
   "outputs": [],
   "source": [
    "def load_birth(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-total-female-births.csv\")\n",
    "\n",
    "    # Remove unnamed columns\n",
    "    if 'Unnamed: 2' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 2'])\n",
    "\n",
    "    # Parse date safely\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates (like the description text)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"Births\": \"y\"})\n",
    "\n",
    "    # Convert 'y' to numeric, coercing errors to NaN and dropping them\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "    print(df.shape)\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_birth, frequency='M', horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YpeOSg7wFU1M",
    "outputId": "c4118acd-e768-4200-e7b7-52d102b0db0c"
   },
   "outputs": [],
   "source": [
    "def load_store(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/store.csv\")\n",
    "    df = df[(df['store'] == 0) & (df['product'] == 0)]\n",
    "    df = df.drop(columns=['store', 'product'])\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates (like the description text)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"number_sold\": \"y\"})\n",
    "\n",
    "    # Convert 'y' to numeric, coercing errors to NaN and dropping them\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "    print(df.shape)\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_store, frequency='M', horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cAQ6d1kkFXvE",
    "outputId": "b454ef7a-a2dc-494b-d6b8-beee8a1e08f3"
   },
   "outputs": [],
   "source": [
    "def load_hospitality(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/HospitalityEmployees.csv\")\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates (like the description text)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"Employees\": \"y\"})\n",
    "\n",
    "    # Convert 'y' to numeric, coercing errors to NaN and dropping them\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "    print(df.shape)\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "vit_prediction(load_hospitality, frequency='M', horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "kNYfv75_Fa8s",
    "outputId": "41c528f9-479c-4e2e-fab6-3845ce2d48af"
   },
   "outputs": [],
   "source": [
    "vit_results = pd.DataFrame(RESULTS).T\n",
    "vit_results.to_csv('vit_results.csv', index=True)\n",
    "vit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-JuQHY_Fev8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
