{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8474xITMxJTe"
   },
   "outputs": [],
   "source": [
    "# pip install nixtla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn12Z9Fa0Rwn"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from nixtla import NixtlaClient\n",
    "\n",
    "api_key = \"nixak-rSGRUQqrWwdMVRyIsCiI0kIGBay5yQVS48BNWYEunTRoqYy1P0UtbRev8382bf6whgCtMqotmL1bIXIY\"\n",
    "\n",
    "RESULTS = {}  # reuse your global results dict\n",
    "\n",
    "def log_simple_result(results_dict, dataset_name, horizon, mae, rmse, mape, r2):\n",
    "    results_dict[dataset_name] = {\n",
    "        \"horizon\": horizon,\n",
    "        \"MAE\": round(mae, 2),\n",
    "        \"RMSE\": round(rmse, 2),\n",
    "        \"MAPE (%)\": round(mape, 2),\n",
    "        \"RÂ²\": round(r2, 4)\n",
    "    }\n",
    "\n",
    "def _pick_pred_col(fcst_df):\n",
    "    \"\"\"Heuristically pick the point-forecast column from Nixtla output.\"\"\"\n",
    "    # Common names: 'y_hat', 'TimeGPT', 'forecast', 'yhat', 'y_pred'\n",
    "    candidates = []\n",
    "    for c in fcst_df.columns:\n",
    "        cl = c.lower()\n",
    "        if cl in {\"y_hat\", \"yhat\", \"forecast\", \"timegpt\", \"y_pred\"}:\n",
    "            candidates.append(c)\n",
    "        elif \"y_hat\" in cl or \"yhat\" in cl:\n",
    "            candidates.append(c)\n",
    "    if candidates:\n",
    "        return candidates[0]\n",
    "    # Fallback: last non-key column\n",
    "    key_cols = {\"unique_id\", \"ds\", \"y\"}\n",
    "    for c in fcst_df.columns[::-1]:\n",
    "        if c not in key_cols:\n",
    "            return c\n",
    "    raise ValueError(\"Could not identify forecast column in fcst_df.\")\n",
    "\n",
    "def _pick_interval_cols(fcst_df, level=80):\n",
    "    \"\"\"Try to find lower/upper interval columns for a given level.\"\"\"\n",
    "    lvl = str(level)\n",
    "    lower_candidates = [c for c in fcst_df.columns if any(s in c.lower() for s in [f\"lo-{lvl}\", f\"y_hat_lo-{lvl}\", f\"lower_{lvl}\"])]\n",
    "    upper_candidates = [c for c in fcst_df.columns if any(s in c.lower() for s in [f\"hi-{lvl}\", f\"y_hat_hi-{lvl}\", f\"upper_{lvl}\"])]\n",
    "    lo = lower_candidates[0] if lower_candidates else None\n",
    "    hi = upper_candidates[0] if upper_candidates else None\n",
    "    return lo, hi\n",
    "\n",
    "def timegpt_prediction(\n",
    "    dataset,\n",
    "    horizon=24,\n",
    "    frequency=\"M\",\n",
    "    dataset_name=None,\n",
    "    results_dict=RESULTS,\n",
    "    api_key=None,\n",
    "    level=(80, 90),\n",
    "    client_kwargs=None,\n",
    "    forecast_kwargs=None,\n",
    "):\n",
    "\n",
    "\n",
    "    # 1) Load dataset\n",
    "    train_df, test_df = dataset(horizon=horizon)\n",
    "    uid = train_df[\"unique_id\"].iloc[0]\n",
    "\n",
    "    # 2) Instantiate client\n",
    "    client_kwargs = client_kwargs or {}\n",
    "    nixtla_client = NixtlaClient(api_key=api_key, **client_kwargs)\n",
    "\n",
    "    # 3) Prepare train in Nixtla format\n",
    "    train_nixtla = train_df[[\"unique_id\", \"ds\", \"y\"]].copy()\n",
    "    train_nixtla[\"ds\"] = pd.to_datetime(train_nixtla[\"ds\"])\n",
    "\n",
    "    # 4) Forecast next `horizon` from end of train\n",
    "    forecast_kwargs = forecast_kwargs or {}\n",
    "    fcst_df = nixtla_client.forecast(\n",
    "        train_nixtla,\n",
    "        h=horizon,\n",
    "        level=list(level) if level else None,\n",
    "        **forecast_kwargs\n",
    "    )\n",
    "\n",
    "    # 5) Align predictions with test horizon\n",
    "    fcst_uid = fcst_df[fcst_df[\"unique_id\"] == uid].sort_values(\"ds\")\n",
    "    pred_col = _pick_pred_col(fcst_uid)\n",
    "    preds = fcst_uid.tail(horizon)[pred_col].to_numpy()\n",
    "\n",
    "    # Actuals\n",
    "    actuals = test_df[\"y\"].to_numpy()\n",
    "\n",
    "    # 6) Metrics\n",
    "    mae = mean_absolute_error(actuals, preds)\n",
    "    rmse = math.sqrt(mean_squared_error(actuals, preds))\n",
    "    mape = np.mean(np.abs((actuals - preds) / np.clip(actuals, 1e-8, None))) * 100\n",
    "    r2 = 1 - np.sum((actuals - preds) ** 2) / np.sum((actuals - np.mean(actuals)) ** 2)\n",
    "\n",
    "    # 7) Save results\n",
    "    name = dataset_name or getattr(dataset, \"__name__\", \"unnamed_dataset\")\n",
    "    log_simple_result(results_dict, name, horizon, mae, rmse, mape, r2)\n",
    "\n",
    "    # 8) Plot (with intervals if available)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_df[\"ds\"], train_df[\"y\"], label=\"Train\")\n",
    "    plt.plot(test_df[\"ds\"], actuals, label=\"Actual\", marker=\"o\")\n",
    "    plt.plot(test_df[\"ds\"], preds, label=f\"Forecast ({pred_col})\", marker=\"x\")\n",
    "\n",
    "    # Try 1st level for band\n",
    "    band_level = level[0] if level else None\n",
    "    if band_level is not None:\n",
    "        lo_col, hi_col = _pick_interval_cols(fcst_uid, level=band_level)\n",
    "        if lo_col and hi_col:\n",
    "            band = fcst_uid.tail(horizon)\n",
    "            plt.fill_between(\n",
    "                test_df[\"ds\"],\n",
    "                band[lo_col].to_numpy(),\n",
    "                band[hi_col].to_numpy(),\n",
    "                alpha=0.25,\n",
    "                label=f\"{band_level}% PI\"\n",
    "            )\n",
    "\n",
    "    plt.title(f\"{name} Forecast - Nixtla/TimeGPT (H={horizon})\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "uoSmzLlC2u01",
    "outputId": "8e4d9690-1b3f-4803-d5d6-3ecfc0d5b837"
   },
   "outputs": [],
   "source": [
    "def load_air_passengers(horizon=24, unique_id=\"AP1\"):\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "    # Standardize column names\n",
    "    df['Month'] = pd.to_datetime(df['Month'])\n",
    "    df = df.rename(columns={\"Month\": \"ds\", \"Passengers\": \"y\"})\n",
    "    print(df.shape)\n",
    "    print('Mean: ', df['y'].mean())\n",
    "\n",
    "    # Split train/test\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "# Reuse your existing loader\n",
    "timegpt_prediction(\n",
    "    dataset=load_air_passengers,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "XIhfzHcc2_ze",
    "outputId": "5b046d0b-effe-4583-b716-dae135bb4e6d"
   },
   "outputs": [],
   "source": [
    "def load_air_sunsopts(horizon=24, unique_id=\"AP1\"):\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Sunspots.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    print(df.shape)\n",
    "\n",
    "    # Standardize column names\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"Monthly Mean Total Sunspot Number\": \"y\"})\n",
    "    print('Mean: ', df['y'].mean())\n",
    "\n",
    "    # Split train/test\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "# Reuse your existing loader\n",
    "timegpt_prediction(\n",
    "    dataset=load_air_sunsopts,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KxtQTXV23Xog",
    "outputId": "1387ef9a-55b2-4e62-a713-1ce510847e63"
   },
   "outputs": [],
   "source": [
    "def load_temp_daily(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/temp.csv\")\n",
    "\n",
    "    if 'Unnamed: 2' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 2'])\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"temp\": \"y\"})\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    # Ensure daily regularity: sort, drop dupes, reindex full daily range\n",
    "    df = df.sort_values('ds').drop_duplicates('ds')\n",
    "    full_idx = pd.date_range(df['ds'].min(), df['ds'].max(), freq='D')\n",
    "    df = df.set_index('ds').reindex(full_idx)\n",
    "    df.index.name = 'ds'\n",
    "\n",
    "    # Fill small gaps if needed\n",
    "    df['y'] = df['y'].interpolate(limit_direction='both')\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df  = df.iloc[-horizon:].copy()\n",
    "\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id']  = unique_id\n",
    "\n",
    "    return train_df.reset_index().rename(columns={'index':'ds'})[['unique_id','ds','y']], \\\n",
    "           test_df.reset_index().rename(columns={'index':'ds'})[['unique_id','ds','y']]\n",
    "\n",
    "# Use daily frequency here:\n",
    "timegpt_prediction(\n",
    "    dataset=load_temp_daily,\n",
    "    horizon=24,            # 24 days ahead\n",
    "    frequency='D',         # <-- daily\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "O87EkCjw3jpP",
    "outputId": "e73c63bf-f879-4174-919f-2fbd0a5da964"
   },
   "outputs": [],
   "source": [
    "def load_temperature(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Temperature'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Temperature:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "timegpt_prediction(\n",
    "    dataset=load_temperature,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "okMyATUY4P7o",
    "outputId": "86ec1d6b-5ca8-4602-efe6-d341b952b209"
   },
   "outputs": [],
   "source": [
    "def load_precipitation(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Precipitation'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Precipitation:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "timegpt_prediction(\n",
    "    dataset=load_precipitation,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "id": "DVSNQl184YWI",
    "outputId": "cdfdb8d8-1c28-43b0-974c-231afe60d1c7"
   },
   "outputs": [],
   "source": [
    "def load_humidity(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Specific Humidity'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Specific Humidity:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "timegpt_prediction(\n",
    "    dataset=load_humidity,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A2Pd01r24ydf",
    "outputId": "a4a3872a-bdab-4c85-fdb0-e3cd4585a1fc"
   },
   "outputs": [],
   "source": [
    "def load_relative_humidity(horizon=24, unique_id=\"AP1\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/Rainfall_data.csv\")\n",
    "\n",
    "    # Create timestamp from Year, Month, Day\n",
    "    df['ds'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "    # Use Temperature column as 'y'\n",
    "    df['y'] = pd.to_numeric(df['Relative Humidity'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean Relative Humidity:', df['y'].mean())\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "timegpt_prediction(\n",
    "    dataset=load_relative_humidity,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A-QLi-TG5CXq",
    "outputId": "372c97aa-5cec-4a36-ba92-5df2a90d2b0e"
   },
   "outputs": [],
   "source": [
    "def load_birth(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-total-female-births.csv\")\n",
    "\n",
    "    # Remove unnamed columns\n",
    "    if 'Unnamed: 2' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 2'])\n",
    "\n",
    "    # Parse date safely\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates (like the description text)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"Births\": \"y\"})\n",
    "\n",
    "    # Convert 'y' to numeric, coercing errors to NaN and dropping them\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "    print(df.shape)\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "timegpt_prediction(\n",
    "    dataset=load_birth,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EnHP0MBf5pKB",
    "outputId": "02303513-eb14-4854-d01d-856eb30f09b1"
   },
   "outputs": [],
   "source": [
    "def load_store(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/store.csv\")\n",
    "    df = df[(df['store'] == 0) & (df['product'] == 0)]\n",
    "    df = df.drop(columns=['store', 'product'])\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates (like the description text)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"number_sold\": \"y\"})\n",
    "\n",
    "    # Convert 'y' to numeric, coercing errors to NaN and dropping them\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "    print(df.shape)\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "timegpt_prediction(\n",
    "    dataset=load_store,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fId1A6xA5uTE",
    "outputId": "4d5723a1-9a01-4d58-9bba-bd3f45862059"
   },
   "outputs": [],
   "source": [
    "def load_hospitality(horizon=24, unique_id=\"AP1\"):\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ahamed14051/time-series-dataset/refs/heads/main/HospitalityEmployees.csv\")\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates (like the description text)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\"Date\": \"ds\", \"Employees\": \"y\"})\n",
    "\n",
    "    # Convert 'y' to numeric, coercing errors to NaN and dropping them\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    print('Mean:', df['y'].mean())\n",
    "    print(df.shape)\n",
    "\n",
    "    # Train/test split\n",
    "    train_df = df.iloc[:-horizon].copy()\n",
    "    test_df = df.iloc[-horizon:].copy()\n",
    "\n",
    "    # Add unique_id\n",
    "    train_df['unique_id'] = unique_id\n",
    "    test_df['unique_id'] = unique_id\n",
    "\n",
    "    return train_df[['unique_id', 'ds', 'y']], test_df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "timegpt_prediction(\n",
    "    dataset=load_hospitality,\n",
    "    horizon=24,\n",
    "    frequency='M',\n",
    "    api_key=api_key,\n",
    "    level=(80, 90)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIjWJFYZ51NL"
   },
   "outputs": [],
   "source": [
    "timeGPT_results = pd.DataFrame(RESULTS).T\n",
    "timeGPT_results.to_csv('timeGPT_results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ykJbTMkh57Eo",
    "outputId": "07f32ac7-c05b-4b80-e538-a44a9a82fd15"
   },
   "outputs": [],
   "source": [
    "timeGPT_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pZQdeGk58Qc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
